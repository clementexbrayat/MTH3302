{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# MTH3302 : Méthodes probabilistes et statistiques pour l'I.A.\n",
    "\n",
    "Jonathan Jalbert<br/>\n",
    "Professeur adjoint au Département de mathématiques et de génie industriel<br/>\n",
    "Polytechnique Montréal<br/>\n",
    "\n",
    "Le projet a été développé à l'aide de Alice Breton, étudiante à la maîtrise en génie informatique. Elle a suivi le cours lors de la session Hiver 2019.\n",
    "\n",
    "\n",
    "\n",
    "# Projet : Débordement d'égouts\n",
    "\n",
    "La description du projet est disponible à l'adresse suivante :\n",
    "https://www.kaggle.com/t/a238b752c33a41d9803c2cdde6bfc929\n",
    "\n",
    "Ce calepin Jupyter de base permet de charger et de nettoyer les données fournies. La dernière section détaille la génération du fichier des prédictions afin de le soumettre sur Kaggle dans le bon format.\n",
    "\n",
    "Dans un premier temps, vous devrez récupérer l'archive *data.zip* sur Moodle. Ce dossier contient les fichiers suivants :\n",
    "- surverses.csv\n",
    "- precipitation.csv\n",
    "- ouvrages-surverses.csv\n",
    "- test.csv\n",
    "\n",
    "Veuillez le décompresser dans le répertoire de ce calepin.\n",
    "\n",
    "Le fichier *surverse.csv* répertorie s'il y a surverse (1) ou non (0) au cours de la journée pour les 170 ouvrages de débordement de 2013 à 2018 pour les mois de mai à octobre (inclusivement). Des renseignements additionnels sur les données sont disponibles à l'adresse suivante :\n",
    "\n",
    "http://donnees.ville.montreal.qc.ca/dataset/debordement\n",
    "\n",
    "\n",
    "Le fichier *precipitation.csv* contient les précipitations horaires en dixième de *mm* enregistrées à 5 stations pluviométriques de 2013 à 2019 :\n",
    "- McTavish (7024745)\n",
    "- Ste-Anne-de-Bellevue (702FHL8)\n",
    "- Montreal/Pierre Elliott Trudeau Intl (702S006)\n",
    "- Montreal/St-Hubert (7027329)\n",
    "- L’Assomption (7014160)\n",
    "\n",
    "Plus d'informations sur les précipitations sont disponibles à l'adresse suivante :\n",
    "\n",
    "https://climat.meteo.gc.ca/climate_data/hourly_data_f.html?hlyRange=2008-01-08%7C2019-11-12&dlyRange=2002-12-23%7C2019-11-12&mlyRange=%7C&StationID=30165&Prov=QC&urlExtension=_f.html&searchType=stnName&optLimit=yearRange&StartYear=1840&EndYear=2019&selRowPerPage=25&Line=17&searchMethod=contains&Month=11&Day=12&txtStationName=montreal&timeframe=1&Year=2019\n",
    "\n",
    "Le fichier *ouvrages-surverses.csv* contient différentes caractéristiques des ouvrages de débordement. \n",
    "\n",
    "http://donnees.ville.montreal.qc.ca/dataset/ouvrage-surverse\n",
    "\n",
    "Le fichier *test.csv* contient les ouvrages et les jours pour lesquels vous devez prédire s'il y a eu surverse (true) ou non (false). Notez que l'on s'intéresse ici à 5 ouvrages de débordement localisés tout autour de l'Ile de Montréal :\n",
    "- 3260-01D dans Rivière-des-Prairies \n",
    "- 3350-07D dans Ahunstic \n",
    "- 4240-01D dans Pointe-aux-Trembles \n",
    "- 4350-01D dans le Vieux-Montréal \n",
    "- 4380-01D dans Verdun\n",
    "\n",
    "#### Remarque\n",
    "\n",
    "Dans le projet, on ne s'intéresse qu'aux surverses occasionnées par les précipitations. On ignore les surverses occasionnées par \n",
    "- fonte de neige (F)\n",
    "- travaux planifiés et entretien (TPL)\n",
    "- urgence (U)\n",
    "- autre (AUT)\n",
    "\n",
    "On suppose que lorsqu'il n'y a pas de raison pour la surverse, il s'agit d'une surverse causée par les précipitations. Puisque Nous nous intéresserons uniquement aux surverses occasionnées par les précipitations liquides, nous ne considérons que les mois de mai à octobre inclusivement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV, DataFrames, Statistics, Dates, Gadfly, GLM, Distributions, LinearAlgebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chargement des données et nettoyage préliminaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des surverses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>NO_OUVRAGE</th><th>DATE</th><th>SURVERSE</th><th>RAISON</th></tr><tr><th></th><th>String</th><th>Date</th><th>Int64⍰</th><th>String⍰</th></tr></thead><tbody><p>5 rows × 4 columns</p><tr><th>1</th><td>0642-01D</td><td>2013-05-01</td><td>0</td><td>missing</td></tr><tr><th>2</th><td>0642-01D</td><td>2013-05-02</td><td>0</td><td>missing</td></tr><tr><th>3</th><td>0642-01D</td><td>2013-05-03</td><td>0</td><td>missing</td></tr><tr><th>4</th><td>0642-01D</td><td>2013-05-04</td><td>0</td><td>missing</td></tr><tr><th>5</th><td>0642-01D</td><td>2013-05-05</td><td>0</td><td>missing</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccc}\n",
       "\t& NO\\_OUVRAGE & DATE & SURVERSE & RAISON\\\\\n",
       "\t\\hline\n",
       "\t& String & Date & Int64⍰ & String⍰\\\\\n",
       "\t\\hline\n",
       "\t1 & 0642-01D & 2013-05-01 & 0 &  \\\\\n",
       "\t2 & 0642-01D & 2013-05-02 & 0 &  \\\\\n",
       "\t3 & 0642-01D & 2013-05-03 & 0 &  \\\\\n",
       "\t4 & 0642-01D & 2013-05-04 & 0 &  \\\\\n",
       "\t5 & 0642-01D & 2013-05-05 & 0 &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "5×4 DataFrame\n",
       "│ Row │ NO_OUVRAGE │ DATE       │ SURVERSE │ RAISON  │\n",
       "│     │ \u001b[90mString\u001b[39m     │ \u001b[90mDate\u001b[39m       │ \u001b[90mInt64⍰\u001b[39m   │ \u001b[90mString⍰\u001b[39m │\n",
       "├─────┼────────────┼────────────┼──────────┼─────────┤\n",
       "│ 1   │ 0642-01D   │ 2013-05-01 │ 0        │ \u001b[90mmissing\u001b[39m │\n",
       "│ 2   │ 0642-01D   │ 2013-05-02 │ 0        │ \u001b[90mmissing\u001b[39m │\n",
       "│ 3   │ 0642-01D   │ 2013-05-03 │ 0        │ \u001b[90mmissing\u001b[39m │\n",
       "│ 4   │ 0642-01D   │ 2013-05-04 │ 0        │ \u001b[90mmissing\u001b[39m │\n",
       "│ 5   │ 0642-01D   │ 2013-05-05 │ 0        │ \u001b[90mmissing\u001b[39m │"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_surverse_init = CSV.read(\"data/surverses.csv\",missingstring=\"-99999\")\n",
    "first(data_surverse_init,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nettoyage des données sur les surverses\n",
    "\n",
    "#### Extraction des surverses pour les mois de mai à octobre inclusivement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>NO_OUVRAGE</th><th>DATE</th><th>SURVERSE</th><th>RAISON</th></tr><tr><th></th><th>String</th><th>Date</th><th>Int64⍰</th><th>String⍰</th></tr></thead><tbody><p>5 rows × 4 columns</p><tr><th>1</th><td>0642-01D</td><td>2013-05-01</td><td>0</td><td>missing</td></tr><tr><th>2</th><td>0642-01D</td><td>2013-05-02</td><td>0</td><td>missing</td></tr><tr><th>3</th><td>0642-01D</td><td>2013-05-03</td><td>0</td><td>missing</td></tr><tr><th>4</th><td>0642-01D</td><td>2013-05-04</td><td>0</td><td>missing</td></tr><tr><th>5</th><td>0642-01D</td><td>2013-05-05</td><td>0</td><td>missing</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccc}\n",
       "\t& NO\\_OUVRAGE & DATE & SURVERSE & RAISON\\\\\n",
       "\t\\hline\n",
       "\t& String & Date & Int64⍰ & String⍰\\\\\n",
       "\t\\hline\n",
       "\t1 & 0642-01D & 2013-05-01 & 0 &  \\\\\n",
       "\t2 & 0642-01D & 2013-05-02 & 0 &  \\\\\n",
       "\t3 & 0642-01D & 2013-05-03 & 0 &  \\\\\n",
       "\t4 & 0642-01D & 2013-05-04 & 0 &  \\\\\n",
       "\t5 & 0642-01D & 2013-05-05 & 0 &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "5×4 DataFrame\n",
       "│ Row │ NO_OUVRAGE │ DATE       │ SURVERSE │ RAISON  │\n",
       "│     │ \u001b[90mString\u001b[39m     │ \u001b[90mDate\u001b[39m       │ \u001b[90mInt64⍰\u001b[39m   │ \u001b[90mString⍰\u001b[39m │\n",
       "├─────┼────────────┼────────────┼──────────┼─────────┤\n",
       "│ 1   │ 0642-01D   │ 2013-05-01 │ 0        │ \u001b[90mmissing\u001b[39m │\n",
       "│ 2   │ 0642-01D   │ 2013-05-02 │ 0        │ \u001b[90mmissing\u001b[39m │\n",
       "│ 3   │ 0642-01D   │ 2013-05-03 │ 0        │ \u001b[90mmissing\u001b[39m │\n",
       "│ 4   │ 0642-01D   │ 2013-05-04 │ 0        │ \u001b[90mmissing\u001b[39m │\n",
       "│ 5   │ 0642-01D   │ 2013-05-05 │ 0        │ \u001b[90mmissing\u001b[39m │"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_surverse_init = filter(row -> month(row.DATE) > 4, data_surverse_init) \n",
    "data_surverse_init = filter(row -> month(row.DATE) < 11, data_surverse_init) \n",
    "first(data_surverse_init,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remplacement des valeurs *missing* dans la colonne :RAISON par \"Inconnue\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>NO_OUVRAGE</th><th>DATE</th><th>SURVERSE</th><th>RAISON</th></tr><tr><th></th><th>String</th><th>Date</th><th>Int64⍰</th><th>String</th></tr></thead><tbody><p>5 rows × 4 columns</p><tr><th>1</th><td>0642-01D</td><td>2013-05-01</td><td>0</td><td>Inconnue</td></tr><tr><th>2</th><td>0642-01D</td><td>2013-05-02</td><td>0</td><td>Inconnue</td></tr><tr><th>3</th><td>0642-01D</td><td>2013-05-03</td><td>0</td><td>Inconnue</td></tr><tr><th>4</th><td>0642-01D</td><td>2013-05-04</td><td>0</td><td>Inconnue</td></tr><tr><th>5</th><td>0642-01D</td><td>2013-05-05</td><td>0</td><td>Inconnue</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccc}\n",
       "\t& NO\\_OUVRAGE & DATE & SURVERSE & RAISON\\\\\n",
       "\t\\hline\n",
       "\t& String & Date & Int64⍰ & String\\\\\n",
       "\t\\hline\n",
       "\t1 & 0642-01D & 2013-05-01 & 0 & Inconnue \\\\\n",
       "\t2 & 0642-01D & 2013-05-02 & 0 & Inconnue \\\\\n",
       "\t3 & 0642-01D & 2013-05-03 & 0 & Inconnue \\\\\n",
       "\t4 & 0642-01D & 2013-05-04 & 0 & Inconnue \\\\\n",
       "\t5 & 0642-01D & 2013-05-05 & 0 & Inconnue \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "5×4 DataFrame\n",
       "│ Row │ NO_OUVRAGE │ DATE       │ SURVERSE │ RAISON   │\n",
       "│     │ \u001b[90mString\u001b[39m     │ \u001b[90mDate\u001b[39m       │ \u001b[90mInt64⍰\u001b[39m   │ \u001b[90mString\u001b[39m   │\n",
       "├─────┼────────────┼────────────┼──────────┼──────────┤\n",
       "│ 1   │ 0642-01D   │ 2013-05-01 │ 0        │ Inconnue │\n",
       "│ 2   │ 0642-01D   │ 2013-05-02 │ 0        │ Inconnue │\n",
       "│ 3   │ 0642-01D   │ 2013-05-03 │ 0        │ Inconnue │\n",
       "│ 4   │ 0642-01D   │ 2013-05-04 │ 0        │ Inconnue │\n",
       "│ 5   │ 0642-01D   │ 2013-05-05 │ 0        │ Inconnue │"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raison = coalesce.(data_surverse_init[:,:RAISON],\"Inconnue\")\n",
    "data_surverse_init[!,:RAISON] = raison\n",
    "first(data_surverse_init,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exlusion des surverses coccasionnées par d'autres facteurs que les précipitations liquides\n",
    "\n",
    "Ces facteurs correspondent à : \n",
    "- la fonte de neige (F), \n",
    "- les travaux planifiés et entretien (TPL)\n",
    "- urgence (U)\n",
    "- autre (AUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>NO_OUVRAGE</th><th>DATE</th><th>SURVERSE</th></tr><tr><th></th><th>String</th><th>Date</th><th>Int64⍰</th></tr></thead><tbody><p>5 rows × 3 columns</p><tr><th>1</th><td>0642-01D</td><td>2013-05-01</td><td>0</td></tr><tr><th>2</th><td>0642-01D</td><td>2013-05-02</td><td>0</td></tr><tr><th>3</th><td>0642-01D</td><td>2013-05-03</td><td>0</td></tr><tr><th>4</th><td>0642-01D</td><td>2013-05-04</td><td>0</td></tr><tr><th>5</th><td>0642-01D</td><td>2013-05-05</td><td>0</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccc}\n",
       "\t& NO\\_OUVRAGE & DATE & SURVERSE\\\\\n",
       "\t\\hline\n",
       "\t& String & Date & Int64⍰\\\\\n",
       "\t\\hline\n",
       "\t1 & 0642-01D & 2013-05-01 & 0 \\\\\n",
       "\t2 & 0642-01D & 2013-05-02 & 0 \\\\\n",
       "\t3 & 0642-01D & 2013-05-03 & 0 \\\\\n",
       "\t4 & 0642-01D & 2013-05-04 & 0 \\\\\n",
       "\t5 & 0642-01D & 2013-05-05 & 0 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "5×3 DataFrame\n",
       "│ Row │ NO_OUVRAGE │ DATE       │ SURVERSE │\n",
       "│     │ \u001b[90mString\u001b[39m     │ \u001b[90mDate\u001b[39m       │ \u001b[90mInt64⍰\u001b[39m   │\n",
       "├─────┼────────────┼────────────┼──────────┤\n",
       "│ 1   │ 0642-01D   │ 2013-05-01 │ 0        │\n",
       "│ 2   │ 0642-01D   │ 2013-05-02 │ 0        │\n",
       "│ 3   │ 0642-01D   │ 2013-05-03 │ 0        │\n",
       "│ 4   │ 0642-01D   │ 2013-05-04 │ 0        │\n",
       "│ 5   │ 0642-01D   │ 2013-05-05 │ 0        │"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_surverse = filter(row -> row.RAISON ∈ [\"P\",\"Inconnue\",\"TS\"], data_surverse_init) \n",
    "select!(data_surverse, [:NO_OUVRAGE, :DATE, :SURVERSE])\n",
    "select!(data_surverse_init, [:NO_OUVRAGE, :DATE, :SURVERSE])\n",
    "first(data_surverse,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exclusion des lignes où :SURVERSE est manquante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>NO_OUVRAGE</th><th>DATE</th><th>SURVERSE</th></tr><tr><th></th><th>String</th><th>Date</th><th>Int64</th></tr></thead><tbody><p>5 rows × 3 columns</p><tr><th>1</th><td>0642-01D</td><td>2013-05-01</td><td>0</td></tr><tr><th>2</th><td>0642-01D</td><td>2013-05-02</td><td>0</td></tr><tr><th>3</th><td>0642-01D</td><td>2013-05-03</td><td>0</td></tr><tr><th>4</th><td>0642-01D</td><td>2013-05-04</td><td>0</td></tr><tr><th>5</th><td>0642-01D</td><td>2013-05-05</td><td>0</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccc}\n",
       "\t& NO\\_OUVRAGE & DATE & SURVERSE\\\\\n",
       "\t\\hline\n",
       "\t& String & Date & Int64\\\\\n",
       "\t\\hline\n",
       "\t1 & 0642-01D & 2013-05-01 & 0 \\\\\n",
       "\t2 & 0642-01D & 2013-05-02 & 0 \\\\\n",
       "\t3 & 0642-01D & 2013-05-03 & 0 \\\\\n",
       "\t4 & 0642-01D & 2013-05-04 & 0 \\\\\n",
       "\t5 & 0642-01D & 2013-05-05 & 0 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "5×3 DataFrame\n",
       "│ Row │ NO_OUVRAGE │ DATE       │ SURVERSE │\n",
       "│     │ \u001b[90mString\u001b[39m     │ \u001b[90mDate\u001b[39m       │ \u001b[90mInt64\u001b[39m    │\n",
       "├─────┼────────────┼────────────┼──────────┤\n",
       "│ 1   │ 0642-01D   │ 2013-05-01 │ 0        │\n",
       "│ 2   │ 0642-01D   │ 2013-05-02 │ 0        │\n",
       "│ 3   │ 0642-01D   │ 2013-05-03 │ 0        │\n",
       "│ 4   │ 0642-01D   │ 2013-05-04 │ 0        │\n",
       "│ 5   │ 0642-01D   │ 2013-05-05 │ 0        │"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_surverse_init = dropmissing(data_surverse_init, disallowmissing=true)\n",
    "data_surverse = dropmissing(data_surverse, disallowmissing=true)\n",
    "first(data_surverse,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On ne garde que les données de surverse concernant lesouvrages qui nous intéressent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ouvrage1 = \"4350-01D\"\n",
    "ouvrage2 = \"3260-01D\"\n",
    "ouvrage3 = \"3350-07D\"\n",
    "ouvrage4 = \"4240-01D\"\n",
    "ouvrage5 = \"4380-01D\"\n",
    "OUVRAGES = [ouvrage1,ouvrage2,ouvrage3,ouvrage4,ouvrage5]\n",
    "\n",
    "data_surverse_init = filter(row -> row.NO_OUVRAGE ∈ OUVRAGES, data_surverse_init)\n",
    "data_surverse = filter(row -> row.NO_OUVRAGE ∈ OUVRAGES, data_surverse)\n",
    "ns = size(data_surverse,1)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des précipitations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_precipitation = CSV.read(\"data/precipitations.csv\",missingstring=\"-99999\")\n",
    "rename!(data_precipitation, Symbol(\"St-Hubert\")=>:StHubert)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nettoyage des données sur les précipitations\n",
    "\n",
    "#### Extraction des précipitations des mois de mai à octobre inclusivement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_precipitation = filter(row -> month(row.date) > 4, data_precipitation) \n",
    "data_precipitation = filter(row -> month(row.date) < 11, data_precipitation) \n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création des ensembles de test de validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "515\n",
      "0"
     ]
    }
   ],
   "source": [
    "ratio = size(filter(row -> row.SURVERSE == 1, data_surverse),1) / size(data_surverse,1)\n",
    "\n",
    "function séparation()\n",
    "    b = Bernoulli(0.90)  # permet d'avoir un ensemble de validation de la même taille que l'ensemble de test   \n",
    "    #b = Bernoulli(1)      # mettre 1 pour le test final (pour ne pas avoir d'ensemble de validation)\n",
    "    ns = size(data_surverse,1)\n",
    "    V = rand(b,ns)\n",
    "    data_surverse[!,:b] = V\n",
    "\n",
    "    surverse_train_init = filter(row -> row.b == 1, data_surverse) \n",
    "    surverse_valid_init = filter(row -> row.b == 0, data_surverse) \n",
    "\n",
    "    select!(data_surverse, [:NO_OUVRAGE, :DATE, :SURVERSE])\n",
    "    select!(surverse_train_init, [:NO_OUVRAGE, :DATE, :SURVERSE])\n",
    "    select!(surverse_valid_init, [:NO_OUVRAGE, :DATE, :SURVERSE])\n",
    "    return surverse_train_init, surverse_valid_init\n",
    "end\n",
    "\n",
    "surverse_train_init, surverse_valid_init = séparation()\n",
    "ratiobis = size(filter(row -> row.SURVERSE == 1, surverse_valid_init),1) / size(surverse_valid_init,1)\n",
    "\n",
    "# cette boucle permet de s'assuer que l'ensemble de validation est représentatif de l'ensemble d'entrainement\n",
    "while (ratiobis < ratio - 0.03) & (ratiobis > ratio + 0.05)\n",
    "    surverse_train_init, surverse_valid_init = séparation()\n",
    "    ratiobis = size(filter(row -> row.SURVERSE == 1, surverse_valid_init),1) / size(surverse_valid_init,1)\n",
    "end\n",
    "\n",
    "\n",
    "n_train = size(surverse_train_init,1)\n",
    "n_valid = size(surverse_valid_init,1)\n",
    "print(n_valid)\n",
    "print('\\n')\n",
    "print(ns - (n_train + n_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A chaque fois que l'on modifie un coefficient dans les cellules en dessuous, il suffit de relancer le code à partir d'ici ! (à part si on veut changer l'ensemble de test et de validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "surverse_train = copy(surverse_train_init)\n",
    "surverse_valid = copy(surverse_valid_init)\n",
    "surverse_df_init = copy(data_surverse_init)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On remplace les valeurs de précipitation missing par une combinaison linéaire des données des autres stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "precipitation_df = copy(data_precipitation)\n",
    "\n",
    "#McTavish, Bellevue, Assomption, Trudeau, StHubert\n",
    "n_precipitation = size(precipitation_df,1)\n",
    "\n",
    "COEFS=[[0,2,1,100,100],[2,0,1,100,1],[2,1,0,1,2],[100,100,1,0,2],[100,1,1,2,0]]  #on a déterminé ces \n",
    "#coefficients en se basant sur les distances sur la carte, on veut qu'une donnée manquante d'une station soit\n",
    "#en priorité remplacée pas les données ce ses stations les plus proches.\n",
    "COEFS=[[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]]             #permet d'effectuer une moyenne\n",
    "#classique. Etonament l'accuracy est meilleure avec cette méthode.\n",
    "\n",
    "for j=1:5\n",
    "    coefs = COEFS[j]\n",
    "    for i=1:n_precipitation\n",
    "        if isequal(missing, precipitation_df[i,j+2])\n",
    "            s = 0\n",
    "            c = 0\n",
    "            for k=1:5\n",
    "                precipitation_df[i,k+2]\n",
    "                if isequal(missing, precipitation_df[i,k+2])\n",
    "                    s=s\n",
    "                else\n",
    "                    s += precipitation_df[i,k+2] * coefs[k] \n",
    "                    c += coefs[k] \n",
    "                end\n",
    "            end\n",
    "            if c == 0\n",
    "                precipitation_df[i,j+2]  = 0\n",
    "            else \n",
    "                precipitation_df[i,j+2] = floor(s/c)\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On ajoute des données de surverses positives qui sont les données de surverse que l'on a actuellement avec du bruit. Cela permet d'avoir des données de surverse en quantité plus nombreuse par rapport aux données de non-surverse et donc de rendre nottre classificateur plus efficace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff = 10 #pour chaque donnée de surverse que l'on a on ajoute autant de donneés avec du bruit que le\n",
    "#coefficient l'indique\n",
    "#pour 10 on a environ autant de données avec une surverse que de données sans surverse\n",
    "\n",
    "for i=1:n_train\n",
    "    if surverse_train[i, :SURVERSE] == 1\n",
    "        for k=1:coeff\n",
    "            ouvrage = surverse_train[i, :NO_OUVRAGE]\n",
    "            date = surverse_train[i, :DATE]\n",
    "            year = Dates.year(date)\n",
    "            month = Dates.month(date)\n",
    "            day = Dates.day(date)\n",
    "            new_date = Date(year - 10*k,month,day)\n",
    "            ind = findfirst(precipitation_df[:,:date] .== date)\n",
    "            while precipitation_df[ind,:date] .== date\n",
    "                hour = precipitation_df[ind,:heure]\n",
    "                McTavish = precipitation_df[ind,:McTavish]\n",
    "                Bellevue = precipitation_df[ind,:Bellevue]\n",
    "                Assomption = precipitation_df[ind,:Assomption]\n",
    "                Trudeau = precipitation_df[ind,:Trudeau]\n",
    "                StHubert = precipitation_df[ind,:StHubert]\n",
    "                stations = [McTavish, Bellevue, Assomption, Trudeau, StHubert]\n",
    "                for j=1:5\n",
    "                    if stations[j] != 0\n",
    "                        noise = Int64(floor(10 * (rand() - 0.5) + rand()))    #on utilise une loi uniforme pour\n",
    "#le bruit qui semble mieux marcher qu'une loi normale\n",
    "                        if stations[j] + noise >=0\n",
    "                            stations[j] += noise\n",
    "                        end\n",
    "                    end\n",
    "                end\n",
    "                push!(precipitation_df,[new_date, hour, stations[1], stations[2], stations[3], stations[4], stations[5]])\n",
    "                ind += 1\n",
    "            end        \n",
    "            push!(surverse_train,[ouvrage, new_date, 1]) \n",
    "            if size(filter(row -> row.DATE == new_date, surverse_df_init),1)==0\n",
    "                push!(surverse_df_init,[ouvrage1, new_date, 1])\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taille des données de surverse:\n",
      "8514\n",
      "taille des données qui n'ont pas de surverses :\n",
      "4224\n",
      "taille des données qui ont surverses :\n",
      "4290"
     ]
    }
   ],
   "source": [
    "print(\"taille des données de surverse:\\n\")\n",
    "print(size(surverse_train,1))\n",
    "print(\"\\ntaille des données qui n'ont pas de surverses :\\n\")\n",
    "print(size(filter(row -> row.SURVERSE == 0, surverse_train),1))\n",
    "print(\"\\ntaille des données qui ont surverses :\\n\")\n",
    "print(size(filter(row -> row.SURVERSE == 1, surverse_train),1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse exploratoire\n",
    "\n",
    "Cette section consitue une analyse exploratoire superficielle permettant de voir s'il existe un lien entre les précipitations et les surverses.\n",
    "\n",
    "Prenons arbitrairement l'ouvrage de débordement près du Bota-Bota (4350-01D). La station météorologique la plus proche est McTavish. Prenons deux variables explicatives simple :\n",
    "- la somme journalière des précipitations\n",
    "- le taux horaire maximum journalier de précipitations\n",
    "\n",
    "#### Calcul de la quantité journalière de précipitations pour chacune des stations météorologiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pcp_sum = by(precipitation_df, :date,  McTavish = :McTavish=>sum, Bellevue = :Bellevue=>sum, \n",
    "   Assomption = :Assomption=>sum, Trudeau = :Trudeau=>sum, StHubert = :StHubert=>sum)\n",
    "first(pcp_sum ,5)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extraction du taux horaire journalier maximum des précipitations pour chacune des stations météorologiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcp_max = by(precipitation_df, :date,  McTavish = :McTavish=>maximum, Bellevue = :Bellevue=>maximum, \n",
    "   Assomption = :Assomption=>maximum, Trudeau = :Trudeau=>maximum, StHubert = :StHubert=>maximum)\n",
    "first(pcp_max,5)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Au lieu de faire la somme sur toute la journée on fait la somme sur les 2 ou 3 ou il pleut le plus\n",
    "Cependant ces variables n'augmentent pas l'accuracy de notre classificateur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_precipitation = size(precipitation_df,1)\n",
    "n_jour = size(pcp_max,1)\n",
    "\n",
    "pcp_sum2h = copy(pcp_max)\n",
    "pcp_sum2h[!, :McTavish] = zeros(Int64, n_jour)\n",
    "pcp_sum2h[!, :Bellevue] = zeros(Int64, n_jour)\n",
    "pcp_sum2h[!, :Assomption] = zeros(Int64, n_jour)\n",
    "pcp_sum2h[!, :Trudeau] = zeros(Int64, n_jour)\n",
    "pcp_sum2h[!, :StHubert] = zeros(Int64, n_jour)\n",
    "\n",
    "for i=1:n_jour\n",
    "    date = pcp_sum2h[i, :date]\n",
    "    ind_init = findfirst(precipitation_df[:,:date] .== date)\n",
    "    for j=1:5\n",
    "        ind = ind_init\n",
    "        max = 0\n",
    "        jour1 = 0\n",
    "        jour2 = 0\n",
    "        while (ind < n_precipitation) & (precipitation_df[ind,:date] == date)\n",
    "            jour1 = jour2\n",
    "            jour2 = precipitation_df[ind, j+2]\n",
    "            s = jour1 + jour2\n",
    "            if s > max\n",
    "                max = s\n",
    "                pcp_sum2h[i, j+1] = max\n",
    "            end\n",
    "            ind += 1\n",
    "        end\n",
    "    end\n",
    "end\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_precipitation = size(precipitation_df,1)\n",
    "n_jour = size(pcp_max,1)\n",
    "\n",
    "pcp_sum3h = copy(pcp_max)\n",
    "pcp_sum3h[!, :McTavish] = zeros(Int64, n_jour)\n",
    "pcp_sum3h[!, :Bellevue] = zeros(Int64, n_jour)\n",
    "pcp_sum3h[!, :Assomption] = zeros(Int64, n_jour)\n",
    "pcp_sum3h[!, :Trudeau] = zeros(Int64, n_jour)\n",
    "pcp_sum3h[!, :StHubert] = zeros(Int64, n_jour)\n",
    "\n",
    "for i=1:n_jour\n",
    "    date = pcp_sum3h[i, :date]\n",
    "    ind_init = findfirst(precipitation_df[:,:date] .== date)\n",
    "    for j=1:5\n",
    "        ind = ind_init\n",
    "        max = 0\n",
    "        jour1 = 0\n",
    "        jour2 = 0\n",
    "        jour3 = 0\n",
    "        while (ind < n_precipitation) & (precipitation_df[ind,:date] == date)\n",
    "            jour1 = jour2\n",
    "            jour2 = jour3\n",
    "            jour3 = precipitation_df[ind, j+2]\n",
    "            s = jour1 + jour2 + jour3\n",
    "            if s > max\n",
    "                max = s\n",
    "                pcp_sum3h[i, j+1] = max\n",
    "            end\n",
    "            ind += 1\n",
    "        end\n",
    "    end\n",
    "end\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrainement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons choisi d'utiliser une régression logistique car les données à derterminer sont binaires et donc ce modèle s'applique bien. \n",
    "Après avoir testé différentes combinaisons de variables, celles qui fonctionnent le mieux sont les 5 variables de somme et les 5 variables de maximum. Nous mettons les variables des 5 stations même si certaines sont plus proches que d'autres car notre fonction de régression se chargera d'attribuer des coefficients de régression plus ou moins important à chaque station. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = filter(row -> row.NO_OUVRAGE == ouvrage1, surverse_df_init)\n",
    "df1 = filter(row -> row.NO_OUVRAGE == ouvrage1, surverse_train)\n",
    "df2 = filter(row -> row.NO_OUVRAGE == ouvrage2, surverse_train)\n",
    "df3 = filter(row -> row.NO_OUVRAGE == ouvrage3, surverse_train)\n",
    "df4 = filter(row -> row.NO_OUVRAGE == ouvrage4, surverse_train)\n",
    "df5 = filter(row -> row.NO_OUVRAGE == ouvrage5, surverse_train)\n",
    "\n",
    "n = size(df0,1) #max des size des dfs\n",
    "\n",
    "x1 = Array{Union{Missing, Int64}}(missing, n) # variable pour la somme journalière\n",
    "x3 = Array{Union{Missing, Int64}}(missing, n) # variable pour la somme journalière\n",
    "x5 = Array{Union{Missing, Int64}}(missing, n) # variable pour la somme journalière\n",
    "x7 = Array{Union{Missing, Int64}}(missing, n) # variable pour la somme journalière\n",
    "x9 = Array{Union{Missing, Int64}}(missing, n) # variable pour la somme journalière\n",
    "x2 = Array{Union{Missing, Int64}}(missing, n) # variable pour le max journalier\n",
    "x4 = Array{Union{Missing, Int64}}(missing, n) # variable pour le max journalier\n",
    "x6 = Array{Union{Missing, Int64}}(missing, n) # variable pour le max journalier\n",
    "x8 = Array{Union{Missing, Int64}}(missing, n) # variable pour le max journalier\n",
    "x10 = Array{Union{Missing, Int64}}(missing, n) # variable pour les 3 hueres d'affilées\n",
    "x11 = Array{Union{Missing, Int64}}(missing, n) # variable pour les 3 hueres d'affilées\n",
    "x12 = Array{Union{Missing, Int64}}(missing, n) # variable pour les 3 hueres d'affilées\n",
    "x13 = Array{Union{Missing, Int64}}(missing, n) # variable pour les 3 hueres d'affilées\n",
    "x14 = Array{Union{Missing, Int64}}(missing, n) # variable pour les 3 hueres d'affilées\n",
    "x15 = Array{Union{Missing, Int64}}(missing, n) # variable pour les 3 hueres d'affilées\n",
    "\n",
    "for i=1:size(df0,1)\n",
    "    \n",
    "    ind1 = findfirst(pcp_sum[:,:date] .== df0[i,:DATE])\n",
    "    ind2 = findfirst(pcp_max[:,:date] .== df0[i,:DATE])\n",
    "    \n",
    "    #McTavish\n",
    "    x1[i] = pcp_sum[ind1,:McTavish]\n",
    "    x2[i] = pcp_max[ind2,:McTavish]\n",
    "    #x11[i] = pcp_3h[ind2,:McTavish]\n",
    "    \n",
    "    #Bellevue\n",
    "    x3[i] = pcp_sum[ind1,:Bellevue]\n",
    "    x4[i] = pcp_max[ind2,:Bellevue]\n",
    "    #x12[i] = pcp_3h[ind2,:Bellevue]\n",
    "    \n",
    "    #Assomption\n",
    "    x5[i] = pcp_sum[ind1,:Assomption]\n",
    "    x6[i] = pcp_max[ind2,:Assomption]\n",
    "    #x13[i] = pcp_3h[ind2,:Assomption]\n",
    "    \n",
    "    #Trudeau\n",
    "    x7[i] = pcp_sum[ind1,:Trudeau]\n",
    "    x8[i] = pcp_max[ind2,:Trudeau]\n",
    "    #x14[i] = pcp_3h[ind2,:Trudeau]\n",
    "    \n",
    "    #StHubert\n",
    "    x9[i] = pcp_sum[ind1,:StHubert]\n",
    "    x10[i] = pcp_max[ind2,:StHubert]\n",
    "    #x15[i] = pcp_3h[ind2,:StHubert]\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons essayé d'introduire une variable pour la saison comme suit, cependant cela n'améliore pas la prédiction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "x21 = zeros(Int64, n)  #printemps\n",
    "x22 = zeros(Int64, n)  #automne\n",
    "\n",
    "for i=1:size(df0,1)\n",
    "    if month(df0[i,:DATE]) < 7 #on est au printemps\n",
    "        x11[i] = 1\n",
    "    elseif month(df0[i,:DATE]) > 9 #on est en automne\n",
    "        x12[i] = 1\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = [df1,df2,df3,df4,df5]\n",
    "for df in DF\n",
    "    x1c=copy(x1)\n",
    "    x2c=copy(x2)\n",
    "    x3c=copy(x3)\n",
    "    x4c=copy(x4)\n",
    "    x5c=copy(x5)\n",
    "    x6c=copy(x6)\n",
    "    x7c=copy(x7)\n",
    "    x8c=copy(x8)\n",
    "    x9c=copy(x9)\n",
    "    x10c=copy(x10)\n",
    "    x11c=copy(x11)\n",
    "    x12c=copy(x12)\n",
    "    x13c=copy(x13)\n",
    "    x14c=copy(x14)\n",
    "    x15c=copy(x15)\n",
    "    Xc = [x1c,x2c,x3c,x4c,x5c,x6c,x7c,x8c,x9c,x10c,x11c,x12c,x13c,x14c,x15c]\n",
    "    for j=1:size(df0,1)\n",
    "        i = size(df0,1) + 1 - j\n",
    "        date = df0[i,:DATE]\n",
    "        if size(filter(row -> row.DATE == date, df),1)==0\n",
    "            for k=1:size(Xc,1)\n",
    "                deleteat!(Xc[k], i)\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    df[!,:x1] = x1c\n",
    "    df[!,:x2] = x2c\n",
    "    df[!,:x3] = x3c\n",
    "    df[!,:x4] = x4c\n",
    "    df[!,:x5] = x5c\n",
    "    df[!,:x6] = x6c\n",
    "    df[!,:x7] = x7c\n",
    "    df[!,:x8] = x8c\n",
    "    df[!,:x9] = x9c\n",
    "    df[!,:x10] = x10c\n",
    "    df[!,:x11] = x11c\n",
    "    df[!,:x12] = x12c\n",
    "    df[!,:x13] = x13c\n",
    "    df[!,:x14] = x14c\n",
    "    df[!,:x15] = x15c\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "M1 = glm(@formula(SURVERSE ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10), df1,  Bernoulli(), LogitLink())\n",
    "M2 = glm(@formula(SURVERSE ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10), df2,  Bernoulli(), LogitLink())\n",
    "M3 = glm(@formula(SURVERSE ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10), df3,  Bernoulli(), LogitLink())\n",
    "M4 = glm(@formula(SURVERSE ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10), df4,  Bernoulli(), LogitLink())\n",
    "M5 = glm(@formula(SURVERSE ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10), df5,  Bernoulli(), LogitLink())\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ne pas exécuter les cellules qui suivent si l'on a pas créé d'ensemble de validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1v = filter(row -> row.NO_OUVRAGE == ouvrage1, surverse_valid)\n",
    "df2v = filter(row -> row.NO_OUVRAGE == ouvrage2, surverse_valid)\n",
    "df3v = filter(row -> row.NO_OUVRAGE == ouvrage3, surverse_valid)\n",
    "df4v = filter(row -> row.NO_OUVRAGE == ouvrage4, surverse_valid)\n",
    "df5v = filter(row -> row.NO_OUVRAGE == ouvrage5, surverse_valid)\n",
    "\n",
    "nv = size(df0,1)\n",
    "\n",
    "x1v = Array{Union{Missing, Int64}}(missing, n) # variable pour la somme journalière\n",
    "x3v = Array{Union{Missing, Int64}}(missing, n) # variable pour la somme journalière\n",
    "x5v = Array{Union{Missing, Int64}}(missing, n) # variable pour la somme journalière\n",
    "x7v = Array{Union{Missing, Int64}}(missing, n) # variable pour la somme journalière\n",
    "x9v = Array{Union{Missing, Int64}}(missing, n) # variable pour la somme journalière\n",
    "x2v = Array{Union{Missing, Int64}}(missing, n) # variable pour le max journalier\n",
    "x4v = Array{Union{Missing, Int64}}(missing, n) # variable pour le max journalier\n",
    "x6v = Array{Union{Missing, Int64}}(missing, n) # variable pour le max journalier\n",
    "x8v = Array{Union{Missing, Int64}}(missing, n) # variable pour le max journalier\n",
    "x10v = Array{Union{Missing, Int64}}(missing, n) # variable pour le max journalier\n",
    "\n",
    "for i=1:nv\n",
    "    \n",
    "    ind1 = findfirst(pcp_sum[:,:date] .== df0[i,:DATE])\n",
    "    ind2 = findfirst(pcp_max[:,:date] .== df0[i,:DATE])\n",
    "    \n",
    "    #McTavish\n",
    "    x1v[i] = pcp_sum[ind1,:McTavish]\n",
    "    x2v[i] = pcp_max[ind2,:McTavish]\n",
    "    \n",
    "    #Bellevue\n",
    "    x3v[i] = pcp_sum[ind1,:Bellevue]\n",
    "    x4v[i] = pcp_max[ind2,:Bellevue]\n",
    "    \n",
    "    #Assomption\n",
    "    x5v[i] = pcp_sum[ind1,:Assomption]\n",
    "    x6v[i] = pcp_max[ind2,:Assomption]\n",
    "    \n",
    "    #Trudeau\n",
    "    x7v[i] = pcp_sum[ind1,:Trudeau]\n",
    "    x8v[i] = pcp_max[ind2,:Trudeau]\n",
    "    \n",
    "    #StHubert\n",
    "    x9v[i] = pcp_sum[ind1,:StHubert]\n",
    "    x10v[i] = pcp_max[ind2,:StHubert]\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df01v = copy(df0[!,:DATE])\n",
    "df02v = copy(df0[!,:DATE])\n",
    "df03v = copy(df0[!,:DATE])\n",
    "df04v = copy(df0[!,:DATE])\n",
    "df05v = copy(df0[!,:DATE])\n",
    "DF0 = [df01v,df02v,df03v,df04v,df05v]\n",
    "\n",
    "DF = [df1v,df2v,df3v,df4v,df5v]\n",
    "for k=1:5\n",
    "    df = DF[k]\n",
    "    x1c=copy(x1v)\n",
    "    x2c=copy(x2v)\n",
    "    x3c=copy(x3v)\n",
    "    x4c=copy(x4v)\n",
    "    x5c=copy(x5v)\n",
    "    x6c=copy(x6v)\n",
    "    x7c=copy(x7v)\n",
    "    x8c=copy(x8v)\n",
    "    x9c=copy(x9v)\n",
    "    x10c=copy(x10v)\n",
    "    x11c=copy(x11)\n",
    "    x12c=copy(x12)\n",
    "    Xc = [x1c,x2c,x3c,x4c,x5c,x6c,x7c,x8c,x9c,x10c,x11c,x12c]\n",
    "    for j=1:size(df0,1)\n",
    "        i = size(df0,1) + 1 - j\n",
    "        date = df0[i,:DATE]\n",
    "        if size(filter(row -> row.DATE == date, df),1)==0\n",
    "            for xic in Xc\n",
    "                deleteat!(xic, i)\n",
    "            end\n",
    "            deleteat!(DF0[k],i)\n",
    "        end\n",
    "    end\n",
    "    df[!,:x0] = ones(Int64,length(x1c))\n",
    "    df[!,:x1] = x1c\n",
    "    df[!,:x2] = x2c\n",
    "    df[!,:x3] = x3c\n",
    "    df[!,:x4] = x4c\n",
    "    df[!,:x5] = x5c\n",
    "    df[!,:x6] = x6c\n",
    "    df[!,:x7] = x7c\n",
    "    df[!,:x8] = x8c\n",
    "    df[!,:x9] = x9c\n",
    "    df[!,:x10] = x10c\n",
    "    df[!,:x11] = Xc[11]\n",
    "    df[!,:x12] = Xc[12]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "select!(df1v, [:x0, :x1, :x2, :x3, :x4, :x5, :x6, :x7, :x8, :x9, :x10])\n",
    "teta1v = predict(M1,df1v) \n",
    "select!(df2v, [:x0, :x1, :x2, :x3, :x4, :x5, :x6, :x7, :x8, :x9, :x10])\n",
    "teta2v = predict(M2,df2v) \n",
    "select!(df3v, [:x0, :x1, :x2, :x3, :x4, :x5, :x6, :x7, :x8, :x9, :x10])\n",
    "teta3v = predict(M3,df3v) \n",
    "select!(df4v, [:x0, :x1, :x2, :x3, :x4, :x5, :x6, :x7, :x8, :x9, :x10])\n",
    "teta4v = predict(M4,df4v) \n",
    "select!(df5v, [:x0, :x1, :x2, :x3, :x4, :x5, :x6, :x7, :x8, :x9, :x10])\n",
    "teta5v = predict(M5,df5v) \n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y1v = zeros(Int64,size(df1v,1))\n",
    "Y2v = zeros(Int64,size(df2v,1))\n",
    "Y3v = zeros(Int64,size(df3v,1))\n",
    "Y4v = zeros(Int64,size(df4v,1))\n",
    "Y5v = zeros(Int64,size(df5v,1))\n",
    "\n",
    "Y1v[teta1v.>.5] .= 1\n",
    "Y2v[teta2v.>.5] .= 1\n",
    "Y3v[teta3v.>.5] .= 1\n",
    "Y4v[teta4v.>.5] .= 1\n",
    "Y5v[teta5v.>.5] .= 1\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Permet de calculer le Fscore sur l'ensemble de validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le Fscore obtenu est : 0.7777777777777777"
     ]
    }
   ],
   "source": [
    "TP = 0\n",
    "FP = 0\n",
    "FN = 0\n",
    "TN = 0\n",
    "\n",
    "for i=1:n_valid\n",
    "    ouvrage = surverse_valid[i,:NO_OUVRAGE]\n",
    "    date = surverse_valid[i,:DATE]\n",
    "    if ouvrage == ouvrage1\n",
    "        ind = findfirst(df01v[:] .== date)\n",
    "        prediction = Y1v[ind]\n",
    "    end\n",
    "    if ouvrage == ouvrage2\n",
    "        ind = findfirst(df02v[:] .== date)\n",
    "        prediction = Y2v[ind]\n",
    "    end\n",
    "    if ouvrage == ouvrage3\n",
    "        ind = findfirst(df03v[:] .== date)\n",
    "        prediction = Y3v[ind]\n",
    "    end\n",
    "    if ouvrage == ouvrage4\n",
    "        ind = findfirst(df04v[:] .== date)\n",
    "        prediction = Y4v[ind]\n",
    "    end\n",
    "    if ouvrage == ouvrage5\n",
    "        ind = findfirst(df05v[:] .== date)\n",
    "        prediction = Y5v[ind]\n",
    "    end\n",
    "    \n",
    "    if surverse_valid[i,:SURVERSE] == 1\n",
    "        if prediction == 1\n",
    "            TP += 1\n",
    "        else\n",
    "            FN += 1\n",
    "        end\n",
    "    else\n",
    "        if prediction == 1\n",
    "            FP += 1\n",
    "        else\n",
    "            TN += 1\n",
    "        end\n",
    "    end\n",
    "    \n",
    "end\n",
    "\n",
    "precision = TP / (TP + FP)\n",
    "recall = TP / (TP + FN)\n",
    "\n",
    "score = 2 * precision * recall / (precision + recall)\n",
    "print(\"Le Fscore obtenu est : \", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Traçage des distribution de la somme des précipitations en fonction des surverses ou non\n",
    "\n",
    "On remarque que les deux distributions sont très différentes. Ceci suggère que la somme des précipitations à la station McTavish a un effet sur les surverses au Bota-Bota."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot(df1, x=:SURVERSE, y=:x1, Geom.boxplot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Traçage des distribution de la somme des précipitations en fonction des surverses ou non\n",
    "\n",
    "On remarque que les deux distributions sont très différentes. Ceci suggère que le maximum journalier des précipitations à la station McTavish a un effet sur les surverses au Bota-Bota."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot(df, x=:SURVERSE, y=:MAX, Geom.boxplot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création du fichier de prédictions pour soumettre sur Kaggle\n",
    "\n",
    "Dans ce cas-ci, nous prédirons une surverse avec une probabilité de 1/2 sans considérer aucune variable explicative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "283"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chargement du fichier de test\n",
    "test = CSV.read(\"data/test.csv\")\n",
    "\n",
    "# Pour chacune des lignes du fichier test, comportant un ouvrage et une date, une prédiction est requise.\n",
    "# Dans ce cas-ci, utilisons une prédiction les plus naîve. \n",
    "# On prédit avec une chance sur deux qu'il y ait surverse, sans utiliser de variables explicatives\n",
    "n0 = size(test,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_ = filter(row -> row.NO_OUVRAGE == ouvrage1, test)\n",
    "df2_ = filter(row -> row.NO_OUVRAGE == ouvrage2, test)\n",
    "df3_ = filter(row -> row.NO_OUVRAGE == ouvrage3, test)\n",
    "df4_ = filter(row -> row.NO_OUVRAGE == ouvrage4, test)\n",
    "df5_ = filter(row -> row.NO_OUVRAGE == ouvrage5, test)\n",
    "\n",
    "df0_ = copy(df1_[!,:DATE])\n",
    "for df_ in [df2_, df3_, df4_, df5_]\n",
    "    for i=1:size(df_,1)\n",
    "        if (df_[i,:DATE] in df0_)==false\n",
    "            push!(df0_, df_[i,:DATE])\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "n_ = length(df0_)\n",
    "\n",
    "x1_ = Array{Union{Missing, Int64}}(missing, n_) # variable pour la somme journalière\n",
    "x3_ = Array{Union{Missing, Int64}}(missing, n_) # variable pour la somme journalière\n",
    "x5_ = Array{Union{Missing, Int64}}(missing, n_) # variable pour la somme journalière\n",
    "x7_ = Array{Union{Missing, Int64}}(missing, n_) # variable pour la somme journalière\n",
    "x9_ = Array{Union{Missing, Int64}}(missing, n_) # variable pour la somme journalière\n",
    "x2_ = Array{Union{Missing, Int64}}(missing, n_) # variable pour le max journalier\n",
    "x4_ = Array{Union{Missing, Int64}}(missing, n_) # variable pour le max journalier\n",
    "x6_ = Array{Union{Missing, Int64}}(missing, n_) # variable pour le max journalier\n",
    "x8_ = Array{Union{Missing, Int64}}(missing, n_) # variable pour le max journalier\n",
    "x10_ = Array{Union{Missing, Int64}}(missing, n_) # variable pour le max journalier\n",
    "\n",
    "for i=1:n_\n",
    "    \n",
    "    ind1 = findfirst(pcp_sum[:,:date] .== df0_[i])\n",
    "    ind2 = findfirst(pcp_max[:,:date] .== df0_[i])\n",
    "    \n",
    "    #McTavish\n",
    "    x1_[i] = pcp_sum[ind1,:McTavish]\n",
    "    x2_[i] = pcp_max[ind2,:McTavish]\n",
    "    \n",
    "    #Bellevue\n",
    "    x3_[i] = pcp_sum[ind1,:Bellevue]\n",
    "    x4_[i] = pcp_max[ind2,:Bellevue]\n",
    "    \n",
    "    #Assomption\n",
    "    x5_[i] = pcp_sum[ind1,:Assomption]\n",
    "    x6_[i] = pcp_max[ind2,:Assomption]\n",
    "    \n",
    "    #Trudeau\n",
    "    x7_[i] = pcp_sum[ind1,:Trudeau]\n",
    "    x8_[i] = pcp_max[ind2,:Trudeau]\n",
    "    \n",
    "    #StHubert\n",
    "    x9_[i] = pcp_sum[ind1,:StHubert]\n",
    "    x10_[i] = pcp_max[ind2,:StHubert]\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#variables pour la saison\n",
    "\n",
    "x11_ = zeros(Int64, n_)  #printemps\n",
    "x12_ = zeros(Int64, n_)  #automne\n",
    "\n",
    "for i=1:n_\n",
    "    if month(df0_[i]) < 7 #on est au printemps\n",
    "        x11_[i] = 1\n",
    "    elseif month(df0_[i]) > 9 #on est en automne\n",
    "        x12_[i] = 1\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df01 = copy(df0_)\n",
    "df02 = copy(df0_)\n",
    "df03 = copy(df0_)\n",
    "df04 = copy(df0_)\n",
    "df05 = copy(df0_)\n",
    "DF0 = [df01,df02,df03,df04,df05]\n",
    "\n",
    "DF = [df1_,df2_,df3_,df4_,df5_]\n",
    "for k=1:5\n",
    "    df_ = DF[k]\n",
    "    x1_c=copy(x1_)\n",
    "    x2_c=copy(x2_)\n",
    "    x3_c=copy(x3_)\n",
    "    x4_c=copy(x4_)\n",
    "    x5_c=copy(x5_)\n",
    "    x6_c=copy(x6_)\n",
    "    x7_c=copy(x7_)\n",
    "    x8_c=copy(x8_)\n",
    "    x9_c=copy(x9_)\n",
    "    x10_c=copy(x10_)\n",
    "    x11_c=copy(x11_)\n",
    "    x12_c=copy(x12_)\n",
    "    X_c = [x1_c,x2_c,x3_c,x4_c,x5_c,x6_c,x7_c,x8_c,x9_c,x10_c,x11_c,x12_c]\n",
    "    for j=1:length(df0_)\n",
    "        i = length(df0_) + 1 - j\n",
    "        date = df0_[i]\n",
    "        if size(filter(row -> row.DATE == date, df_),1)==0\n",
    "            for xi_c in X_c\n",
    "                deleteat!(xi_c, i)\n",
    "            end\n",
    "            deleteat!(DF0[k],i)\n",
    "        end\n",
    "    end\n",
    "    df_[!,:x0] = ones(Int64,length(x1_c))\n",
    "    df_[!,:x1] = x1_c\n",
    "    df_[!,:x2] = x2_c\n",
    "    df_[!,:x3] = x3_c\n",
    "    df_[!,:x4] = x4_c\n",
    "    df_[!,:x5] = x5_c\n",
    "    df_[!,:x6] = x6_c\n",
    "    df_[!,:x7] = x7_c\n",
    "    df_[!,:x8] = x8_c\n",
    "    df_[!,:x9] = x9_c\n",
    "    df_[!,:x10] = x10_c\n",
    "    df_[!,:x11] = X_c[11]\n",
    "    df_[!,:x12] = X_c[12]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "select!(df1_, [:x0, :x1, :x2, :x3, :x4, :x5, :x6, :x7, :x8, :x9, :x10])\n",
    "teta1 = predict(M1,df1_) \n",
    "select!(df2_, [:x0, :x1, :x2, :x3, :x4, :x5, :x6, :x7, :x8, :x9, :x10])\n",
    "teta2 = predict(M2,df2_) \n",
    "select!(df3_, [:x0, :x1, :x2, :x3, :x4, :x5, :x6, :x7, :x8, :x9, :x10])\n",
    "teta3 = predict(M3,df3_) \n",
    "select!(df4_, [:x0, :x1, :x2, :x3, :x4, :x5, :x6, :x7, :x8, :x9, :x10])\n",
    "teta4 = predict(M4,df4_) \n",
    "select!(df5_, [:x0, :x1, :x2, :x3, :x4, :x5, :x6, :x7, :x8, :x9, :x10])\n",
    "teta5 = predict(M5,df5_) \n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y1 = zeros(Int64,size(df1_,1))\n",
    "Y2 = zeros(Int64,size(df2_,1))\n",
    "Y3 = zeros(Int64,size(df3_,1))\n",
    "Y4 = zeros(Int64,size(df4_,1))\n",
    "Y5 = zeros(Int64,size(df5_,1))\n",
    "\n",
    "Y1[teta1.>.5] .= 1\n",
    "Y2[teta2.>.5] .= 1\n",
    "Y3[teta3.>.5] .= 1\n",
    "Y4[teta4.>.5] .= 1\n",
    "Y5[teta5.>.5] .= 1\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Création de surverse test :\n",
    "surverse = zeros(Int64, n0)\n",
    "for i=1:n0\n",
    "    ouvrage = test[i,:NO_OUVRAGE]\n",
    "    date = test[i,:DATE]\n",
    "    if ouvrage == ouvrage1\n",
    "        ind = findfirst(df01[:] .== date)\n",
    "        surverse[i] = Y1[ind]\n",
    "    end\n",
    "    if ouvrage == ouvrage2\n",
    "        ind = findfirst(df02[:] .== date)\n",
    "        surverse[i] = Y2[ind]\n",
    "    end\n",
    "    if ouvrage == ouvrage3\n",
    "        ind = findfirst(df03[:] .== date)\n",
    "        surverse[i] = Y3[ind]\n",
    "    end\n",
    "    if ouvrage == ouvrage4\n",
    "        ind = findfirst(df04[:] .== date)\n",
    "        surverse[i] = Y4[ind]\n",
    "    end\n",
    "    if ouvrage == ouvrage5\n",
    "        ind = findfirst(df05[:] .== date)\n",
    "        surverse[i] = Y5[ind]\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"sampleSubmission.csv\""
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#surverse = rand(n0) .> .5\n",
    "\n",
    "# Création du fichier sampleSubmission.csv pour soumettre sur Kaggle\n",
    "ID = test[:,:NO_OUVRAGE].*\"_\".*string.(test[:,:DATE])\n",
    "sampleSubmission = DataFrame(ID = ID, Surverse=surverse)\n",
    "CSV.write(\"sampleSubmission.csv\",sampleSubmission)\n",
    "\n",
    "# Vous pouvez par la suite déposer le fichier sampleSubmission.csv sur Kaggle.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.2.0",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
